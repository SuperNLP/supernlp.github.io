---
layout: post
title: EMNLP 2018 Thoughts and Notes
---

### This year’s EMNLP was bigger than any ACL conference ever before. With around 2500 attendees, a couple of hundred talks, and a few hundred posters, it was unthinkable to try and keep track of everything. Nevertheless, in this day-after-the-conference blog, bubbling over with ideas, we will do just that. Starting from the first workshop and concluding with Johan Bos’ _Moment of Meaning_, we will attempt to offer a convincing account of what happened in Brussels and what it meant for the future of NLP.


# WNUT 2018

## Using Wikipedia edits in low resource grammatical error correction
### This paper builds a grammatical error correction (GEC) system for German. The authors combine two previously available German learner corpora: Falko and MERLIN to form the new Falko-MERLIN GEC corpus which contain ~24k sentences and their corrections. Next, they use the German Wikipedia edits to create a noisy, but bigger dataset. The ERRANT tool is used to filter this data by using the Falko-MERLIN corpus as the gold standard. A part of the Falko-MERLIN corpus is set aside as development and test sets and the rest is combined with Wikipedia data to train a convolutional seq2seq network to correct grammatical errors. The results show that incorporating the noisy Wikipedia data increases the accuracy of corrections. Including only the filtered part of Wikipedia increases it a bit more.

# Deep Latent Variable Models of Natural Language 
![alt text](
        {{supernlp.github.io}}/assets/img/vae.png  
      )
      
### In this tutorial, Alexander Rush, Yoon Kim, and Sam Wiseman offered a rather dense coverage of a class of models which is becoming more and more widely used in NLP. Latent variable models have been around for a long time in statistical modelling (see: Factor analysis, LISREL, etc.). A latent variable is one which is not directly observed but which is assumed to affect observed variables. Latent variable models therefore attempt to model the underlying structure of the observed variables, offering an explanation of the dependencies between observed variables which are then seen as conditionally independent, given the latent variable(s). 

### The tutorial starts by introducing the types of latent variable models (discrete, continuous, and structured), their connection to deep learning models, and example NLP applications. It then proceeds to explain ELBO, the learning objective commonly used for such models. Inference strategies (exact, sampling, and conjugacy) are then examined before they delve into more advanced topics such as the Gumbel-Softmax. Finally, three recent deep latent variable NLP models and the tricks used to make them work are treated. Overall, this is a great resource for a direction of research that is certain to grow:

### [https://nlp.seas.harvard.edu/latent-nlp-tutorial.html](https://nlp.seas.harvard.edu/latent-nlp-tutorial.html)

# CONLL 2018
## [Sequence Classification with Human Attention](http://aclweb.org/anthology/K18-1030)

### **_Full disclosure:_** this paper comes from our own group, so we might be a little biased here. Speaking of which, a recent theme in the field has been the call for more inductive bias and ways to introduce it. In this paper, the authors connect dots from previous work in our group by combining techniques known from multi-task learning with signals of human language processing. In particular, they use a bidirectional RNN with attention for sequence classification. So far so good, but the interesting part is that the network’s attention mechanism is enticed to more closely model human attention as attested by gaze patterns recorded in eye-tracking experiments. This is achieved through an auxiliary loss which, notably, can be minimized from external gaze data, such that no eye-tracking recordings are needed at test time. The paper shows that across three sentence classification tasks, biasing the machine attention towards human attention leads to consistent performance gains and results in sensible attention patterns that both validate the approach and help analyzing system decisions. 

![alt text](
        {{supernlp.github.io}}/assets/img/award.jpeg  
      )

# Staring into the darkness
![alt text](
        {{supernlp.github.io}}/assets/img/blackbox.png 
      )
      
### Blackbox NLP was one of the most highly anticipated workshops at the conference (not just for me, apparently, 700 registrants!) and it delivered on its promise. The workshop dealt with the problem of interpretability in neural network models: how can we know what is encoded in representations learned by our models? What are they capable of learning and what are they not capable of learning? Inspired by previous work on [representation analysis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605405/) and on examining the [linguistic generalisation learned by neural models](https://arxiv.org/abs/1611.01368), the workshop offered a way forward for dealing with a problem which has long been seen as an elephant in the proverbial NLP room. 

### It kicked off with a talk by __Yoav Goldberg__ which stressed the importance of the recent trend of work which treats NLP models/representations as “Organisms” and constructs hypothesis which are then tested empirically - an approach which is uncommon in computer science. He then described ongoing work on testing the expressive and computational capabilities of and extracting discrete representations from RNNs: [http://proceedings.mlr.press/v80/weiss18a.html](http://proceedings.mlr.press/v80/weiss18a.html), [https://arxiv.org/abs/1808.09357](https://arxiv.org/abs/1808.09357), [https://arxiv.org/abs/1805.04908](https://arxiv.org/abs/1805.04908). 

### Slides: [http://u.cs.biu.ac.il/~yogo/blackbox2018.pdf](http://u.cs.biu.ac.il/~yogo/blackbox2018.pdf)

### In the next talk, it was __Graham Neubig’s__ turn to make the case for incorporating linguistic structure in neural models through latent variable modelling (sound familiar? See the first section in this blog!). Specifically, in the talk Graham describes three recent models:

### 1. 
####   [Multi-space Variational Encoder-Decoder](https://arxiv.org/abs/1704.01691) for labeled sequence transduction with semi-supervised learning which models the meaning of a word (a complex, high-level concept) as a continuous variable (using the reparametrization trick) and the closed-class and interpretable morphological features as discrete variables (using the Gumbel-Softmax). The model performs supervised learning by maximizing the variational lower bound on the marginal log likelihood of the data and annotated labels. For unlabeled data, an autoencoding objective is used to construct a word conditioned on its lemma and the set of discrete latent variables (a proxy for the morphological labels) which is associated with a it. 

### 2.
####  [StructVAE](https://arxiv.org/abs/1806.07832) which again performs semi-supervised learning (with structured latent variables) by employing an off-the-shelf semantic parser to parse natural language into latent meaning representations and a decoder to reconstruct the meaning representations into natural language. This allows both supervised training of the inference model on parallel Natural Language-Meaning representation data, and unsupervised training on natural language alone by maximizing the variational lower bound of the likelihood using REINFORCE. 

### 3.
####  [Unsupervised Learning of Syntactic Structure with Invertible Neural Projections](https://arxiv.org/abs/1808.09111) which uses invertible neural projection (super nifty, ha?) to enable the learning of word embeddings which are conditioned on the latent syntactic representation (e.g. dependency parse) in an unsupervised setting. The usefulness of this is demonstrated for both Unsupervised POS tagging (which is modelled with a markov prior) and unsupervised dependency parsing (DMV). 

### Slides: [http://www.phontron.com/slides/neubig18blackbox.pdf](http://www.phontron.com/slides/neubig18blackbox.pdf)

### Finally it was Leila Wehbe’s turn to awe the predominantly NLP-oriented audience with a fresh perspective from the intersection of machine learning and cognitive science. She presented very exciting work about how the representations from NLP’s various artificial neural network models can be used to analyse complex brain activity (MEG and fMRI) data. Among the findings she presented it was:


### 1. MEG activity (MEG can resolve events with a precision of 10 milliseconds or faster) is well predicted by word embeddings, but poorly predicted by (universal) sentence encoders.

### 2.  For fMRI data (which has a latency of several hundred milliseconds), both word embeddings and sentence encoders can be predictive of brain activity. Here is the catch, though: they predict different regions of the brain! Put very roughly, word embeddings are more predictive of regions associated with initial semantic processing, while sentence encoders (which include context + current word or just context) better predict regions associated with later semantic processing and composition. 

### The talk concludes on a speculative note and with a reference to something I’ve been running into a lot lately, David Marr’s levels of analysis (http://blog.shakirm.com/2013/04/marrs-levels-of-analysis/), which I’ll link to but not further discuss in this blog. Food for thought. 

### Other Highlights:

### + [Interpretable Structure Induction Via Sparse Attention](http://aclweb.org/anthology/W18-5450): _Can dynamic sparse, regularized, constrained and structured tells our models to attend to produce a decision?_
#### + [Understanding Convolutional Neural Networks for Text Classification](https://arxiv.org/pdf/1809.08037.pdf): _What does each filter capture? Which n-grams contribute to the classification?_

